{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "HCI project2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MhZ_LE5Xqxp"
      },
      "source": [
        "# Debiasing Word Embeddings\n",
        "\n",
        "### What are Word Embeddings?\n",
        "\n",
        "Word Embeddings are the result of applying dimensionality reduction techniques to words!\n",
        "\n",
        "They give us dense representations of words, which we hope capture some syntactic and semantic information of the words. These dense representations are a natural tool for us to use if we want to pass words into neural models, and the field of Natural Language Processing (NLP) has used some variants of Word Embeddings extensively.\n",
        "\n",
        "There are many, many, many ways to build word embeddings, but the key intuition comes from the notion that the meaning of a word can by inferred from the types of words it appears next to, or as put by John Firth in 1975: \"You shall know a word by the company it keeps\".\n",
        "\n",
        "Typically, we start with a large corpora of text. We'll use this copora to give us counts of words which occur next to each other, which is a pretty good start. In this matrix, our rows correspond to an \"embedding\" of sorts, where each word's embedding is a word by word count of the words that appear next to it.\n",
        "\n",
        "It's a hyperparameter, to choose how large of a window you use when considering words \"next to each other\", or if you want to do clever things, like weight each word by how distant it is from the word you're looking at.\n",
        "\n",
        "Here's what a word co-occurence matrix looks like:\n",
        "<img src=\"./figs/word-co-occurrence.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
        "<span style=\"font-size:9pt\">source:http://web.stanford.edu/class/cs224u/materials/cs224u-vsm-overview.pdf</span>\n",
        "\n",
        "Each row now captures _something_ about the word it represents, in that words that appear in similar contexts will be closer together. Of course, they might not actually be _that_ close together, since our space is the size of our vocabulary.\n",
        "\n",
        "How big is our Vocabulary? Well, that's another hyperparameter. You can decide to filter out words that don't occur that often, to potentially get rid of noise, etc. But generally, it's going to be close to 300K or 400K. That means our word vectors are of dimension 400,000! Luckily, we can use dimensionality reduction techniques, like the ones you've seen already, to learn a low dimensional representation of this co-occurrence matrix. This will give us low-dimensional (200-300d), dense word vectors to use, so we can operate over them efficiently and pass them into models such as neural networks!\n",
        "\n",
        "Which dimensionality reduction technique should we use? Should we normalize counts? Convert them to probability distributions and minimize things like KL divergence? These are all design choices which can have a big effect on the quality and output of your word vectors.\n",
        "\n",
        "For this assignment, though, we'll be using a very standard set of Word Embeddings, called GloVe (Global Vectors for Word Representations https://nlp.stanford.edu/projects/glove/) These word embeddings were standard in state of the art english NLP models, until very recently.\n",
        "\n",
        "Let's load them up and take a look at them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liJvorXQXqxp"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcLWhv_QXqxp"
      },
      "source": [
        "def load_vecs(path):\n",
        "    \"\"\" Loads in word vectors from path.\n",
        "    Will return a dictionary of word to index, and a matrix of vectors (each word is a row)\n",
        "    \"\"\"\n",
        "    vecs = []\n",
        "    w2i = {}\n",
        "    \n",
        "    with open(path, 'r') as inp:\n",
        "        for line in inp.readlines():\n",
        "            line = line.strip().split()\n",
        "            word = str(line[0])\n",
        "            w2i[word] = len(vecs)\n",
        "            vecs.append(np.array(line[1:], dtype=float))\n",
        "        vecs = np.array([v / norm(v) for v in vecs])\n",
        "        print(f'Read in {vecs.shape[0]} words of size {vecs.shape[1]}')\n",
        "    return w2i, vecs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEbUGezFXqxq",
        "outputId": "51c26fa2-a69c-4fe1-a0cd-2070118a9035"
      },
      "source": [
        "# This might take a little bit to run!\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive',force_remount=True) \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOr2Rmy2Ef5G",
        "outputId": "358e4d34-dd6d-4496-8a6a-3afc7d215765"
      },
      "source": [
        "indxr, wembs = load_vecs('/content/gdrive/MyDrive/glove.6B.300d.txt')\n",
        "indxr_gn, wembs_gn = load_vecs('/content/gdrive/MyDrive/gn-glove1b.300d.txt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read in 400000 words of size 300\n",
            "Read in 142527 words of size 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbTkTm2VXqxq"
      },
      "source": [
        "def similarity(v1, v2):\n",
        "    return np.dot(v1, v2) / (norm(v1) * norm(v2))\n",
        "\n",
        "### TODO: Implement below!\n",
        "\n",
        "def analogy(n, word1, word2, word3):\n",
        "    \"\"\"word1 is to word3 as word2 is to... top n results\"\"\"\n",
        "    i2w = {v:k for k, v in indxr.items()}\n",
        "    vector = wembs[indxr[word2]] - wembs[indxr[word1]] + wembs[indxr[word3]]\n",
        "    remove = [indxr[word2], indxr[word1], indxr[word3]]\n",
        "    # @ is Matrix multiplication \n",
        "    distance = np.array(wembs) @ vector\n",
        "    index = distance.argsort()[-n-3:]\n",
        "    index = np.array([dis for dis in index if dis not in remove ])\n",
        "    index = np.flipud(index[-n:])\n",
        "    vectors = [wembs[ind] for ind in index]\n",
        "    words = [i2w[ind] for ind in index]\n",
        "    return words\n",
        "\n",
        "\n",
        "#   return vectors\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6wojU93Xqxr"
      },
      "source": [
        "We are going to use the cell above to help us evaluate your function.\n",
        "\n",
        "However, you should be curious about this \"analogy\" function! Play around with it in the cell below. Try different words! (Remember that we have a limited vocabulary... You don't need to handle OOV words nicely, but know that your code can crash occasionally if you pass in a word that's not in our vocabulary!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMfgN9FNXqxr",
        "outputId": "c37d2875-85ed-4b9f-9d85-8a94d3509257"
      },
      "source": [
        "### TODO: Implement below!\n",
        "# e.g. print(analogy(10, \"man\", \"boy\", \"woman\"))\n",
        "print(analogy(10, \"man\", \"boy\", \"woman\"))\n",
        "print(analogy(10, \"eat\", \"food\", \"drink\"))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['girl', 'girls', 'mother', 'child', 'daughter', 'pregnant', 'teenage', 'grandmother', 'baby', 'teenager']\n",
            "['drinks', 'beverage', 'beverages', 'drinking', 'beer', 'bottled', 'liquor', 'alcohol', 'products', 'water']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHp9WQQ1Xqxr"
      },
      "source": [
        "### (Gender) Bias in Word Embeddings\n",
        "\n",
        "Word embeddings are a very useful tool in NLP, and they have often helped researchers boost their performance in a variety of tasks. However, recently a large problem has been discovered in these types of word embeddings. They inherit some biases from the data they are trained on which is very harmful, such as mysoginistic or racist stereotypes. This is a **huge** problem, because models which use these embeddings are being deployed into the real word to assist with automation strategies!\n",
        "\n",
        "Let's take a look at some examples of gender bias in our word embeddings, which we'll be focusing on for the rest of this assignment.\n",
        "\n",
        "<p style='color:red'> Do not change the below cell! Make sure you run it as is before turning in your notebook.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjr8-kiOXqxr",
        "outputId": "17e2898a-d34f-4920-e9d2-641520aef39a"
      },
      "source": [
        "print(analogy(10, \"man\", \"woman\", \"programmer\"))\n",
        "print(analogy(10, \"man\", \"woman\", \"doctor\"))\n",
        "# Even names contain these biases!\n",
        "print(analogy(10, \"john\", \"mary\", \"doctor\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['programmers', 'freelance', 'educator', 'businesswoman', 'designer', 'translator', 'technician', 'computer', 'animator', 'homemaker']\n",
            "['physician', 'nurse', 'doctors', 'pregnant', 'dentist', 'medical', 'pharmacist', 'surgeon', 'nurses', 'physicians']\n",
            "['nurse', 'mother', 'woman', 'doctors', 'hospital', 'pregnant', 'physician', 'dentist', 'she', 'sister']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x23ypubjXqxr"
      },
      "source": [
        "What does it look like if we swap the analogy around?\n",
        "\n",
        "<p style='color:red'> Do not change the below cell! Make sure you run it as is before turning in your notebook.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aot6iZ28Xqxr",
        "outputId": "0138461e-b97d-4be9-8aba-fb77f3c9d00a"
      },
      "source": [
        "print(analogy(10, \"woman\", \"man\", \"programmer\"))\n",
        "print(analogy(10, \"woman\", \"man\", \"doctor\"))\n",
        "print(analogy(10, \"mary\", \"john\", \"doctor\"))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['programmers', 'computer', 'software', 'engineer', 'developer', 'animator', 'creator', 'hacker', 'user', 'programming']\n",
            "['physician', 'dr.', 'he', 'brother', 'mr.', 'himself', 'him', 'his', 'medical', 'doctors']\n",
            "['physician', 'surgeon', 'doctors', 'medical', 'he', 'dr.', 'man', 'who', 'his', 'himself']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfo83S6fXqxr"
      },
      "source": [
        "This is obviously problematic. Yet, these word embeddings (the ones you're using right now) **have been used in multiple state of the art systems in NLP!**\n",
        "This is a hot area of research right now, because this poses a huge potential problem as more and more AI systems are starting to be deployed into the real world.\n",
        "\n",
        "We're going to take a look at one method of _debiasing_ these word embeddings, which attempts to _remove gender stereotypes_ while keeping in useful gender information such as \"king and queen\" and \"boy and girl\".\n",
        "The debiasing method we're going to look at is described in [this paper](https://arxiv.org/abs/1607.06520), which is one of the seminal papers on exposing stereotypes and bias in this form.\n",
        "\n",
        "While they use different word embeddings, we've seen that our GloVe embeddings contain similar biases. Their method behaves as follows.\n",
        "\n",
        "They first define a \"gender subspace\" $\\mathcal{B} = (b_1, b_2, ..., b_k)$ composed of _orthogonal vectors_.\n",
        "$k$ is a hyperparameter we choose.\n",
        "\n",
        "$\\mathcal{B}$ is built from a set of pairs of gendered items. The idea here is that $\\mathcal{B}$ captures some notion of the \"direction\" of gender which we're trying to capture.\n",
        "\n",
        "The set of pairs, $S = p_1, p_2, ..., p_n$, is given to you.\n",
        "Each pair contains two words which are considered gendered words whose relation captures some notion of gender, i.e. $S = ${(\"woman\", \"man\"), (\"she\", \"he\")...}\n",
        "\n",
        "Building $\\mathcal{B}$ goes as follows:\n",
        "\n",
        "\n",
        "1. Build up matrix $\\mathbf{C} := \\sum_{i=1}^n (\\vec{w_1} - \\vec{w_2})(\\vec{w_1} - \\vec{w_2})^T + (\\vec{w_2} - \\vec{w_1})(\\vec{w_2} - \\vec{w_1})^T$, for $(w_1, w_2) \\in p_i$.\n",
        "\n",
        "That is, for each pair, subtract each word vector from the other and take the outer product of each resulting vector and add it to $\\mathbf{C}$.\n",
        "In our case, $\\mathbf{C}$'s dimensionality should be 100 by 100.\n",
        "\n",
        "2. Compute the SVD of $\\mathbf{C}$.\n",
        "\n",
        "You can use numpy's ```numpy.linalg.svd``` method for this.\n",
        "\n",
        "3. This will give you a decomposition $\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V} = \\mathbf{C}$. Take the top-$k$ vectors from the decomposition of $\\mathbf{C}$ as the orthogonal vectors defining the space $\\mathcal{B} = (b_1, ..., b_k)$. That is, you should take the first $k$ columns of $\\mathbf{U}$.\n",
        "\n",
        "Again, the intuition here is that we now have some set of vectors which, together, capture some notion of the direction of gender."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_eWMQPRXqxr"
      },
      "source": [
        "# Copy biased embeddings into a new object.\n",
        "debiased_wembs = np.copy(wembs)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6KOcjbjXqxr"
      },
      "source": [
        "from numpy.linalg import svd\n",
        "gender_pairs = [('she', 'he'), ('her', 'his'), ('woman', 'man'), ('mary', 'john'), ('herself', 'himself'), ('daughter', 'son'), ('mother', 'father'), ('gal', 'guy'), ('girl', 'boy'), ('female', 'male')]\n",
        "\n",
        "### TODO: Implement below!\n",
        "\n",
        "def build_gender_subspace(k):\n",
        "    \"\"\" Build up the gender subspace. \n",
        "    The output should be the top set of k vectors from the \n",
        "    SVD decomposition of the C matrix, as defined above.\n",
        "    (numpy svd returns 3 items, the first of which is U.\n",
        "    You should take the first k columns of this matrix)\n",
        "    \"\"\"\n",
        "    dim = wembs[0].shape[0]\n",
        "    C = np.zeros((dim, dim))\n",
        "    for pair in gender_pairs:\n",
        "        v1 = wembs[indxr[pair[0]]]\n",
        "        v2 = wembs[indxr[pair[1]]]\n",
        "        d1 = v1 - v2\n",
        "        d2 = v2 - v1\n",
        "        C += np.outer(d1, d1) + np.outer(d2, d2)\n",
        "    u, s, vh = np.linalg.svd(C, full_matrices=True)\n",
        "    return u[:,:k]"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWhgp_0nXqxr"
      },
      "source": [
        "Now let's build the subspace with $k=10$. You can check that things seem ok by making sure that the dot product between all your $b_i$ vectors is close to zero, since they should be orthogonal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy269o9wXqxr"
      },
      "source": [
        "B = build_gender_subspace(10)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwMFv2XeXqxr"
      },
      "source": [
        "We'll only implement the neutralize\" portion of the hard-debiasing method in the paper, if you're following along.\n",
        "We won't implement equalize or the Soft-Debiasing method, to keep things short :)\n",
        "\n",
        "Once we have our gender subspace $\\mathcal{B}$ composed of our $k$ orthogonal vectors, we can select some choice word $w$ to debias as follows:\n",
        "\n",
        "1. Select the embedding $\\vec{w}$ of word $w$ from our regular, biased embeddings.\n",
        "\n",
        "2. Compute $$\\vec{w_\\mathcal{B}} = \\sum_{j=i}^k (\\vec{w} \\cdot \\vec{b_j}) * \\vec{b_j}$$.\n",
        "\n",
        "3. Compute the new, debiased embedding as $$\\vec{w_{ub}} = (\\vec{w} - \\vec{w_{\\mathcal{B}}}) \\; / \\; || \\vec{w} - \\vec{w_{\\mathcal{B}}} || $$\n",
        "\n",
        "Intuitively, what we are doing is projecting our biased vector $\\vec{w}$ into our gender subspace, and then subtracting the result from $\\vec{w}$.\n",
        "\n",
        "You should implement a function ```debias_word(word)```, which takes one argument: the word to debias. It should use our previously defined subspace ```B``` to compute $\\vec{w_{ub}}$, and you should store the result in the new ```debiased_wembs``` matrix defined above, **in the same index that the word is in the original ```wemb``` matrix**.\n",
        "\n",
        "That is, please do not change the ```wembs``` matrix directly, but save your debiased embeddings in the copy we created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TEwxGNGXqxr"
      },
      "source": [
        "# debias function \n",
        "def debias_word(word):\n",
        "    dim = wembs[0].shape[0]\n",
        "    vector = wembs[indxr[word]]\n",
        "    wB = np.zeros(dim)\n",
        "    for i in range(B.shape[1]):\n",
        "        wB += np.dot(vector, B[:,i]) * B[:,i]\n",
        "    wub = (vector - wB)/(np.linalg.norm(vector - wB))\n",
        "    debiased_wembs[indxr[word]] = wub"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCs_IeUhTmRq"
      },
      "source": [
        "# Calculate the debiased dataset \n",
        "for word in indxr:\n",
        "  debias_word(word)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB7UDu0QGimz"
      },
      "source": [
        "def read_gender_list(filename1, filename2, filename3):\n",
        "    female_list = []\n",
        "    male_list = []\n",
        "    gender_neutral_list = []\n",
        "\n",
        "    with open(filename1, 'r') as f1:\n",
        "      for line in f1:\n",
        "        female_list.append(line.strip())\n",
        "\n",
        "    with open(filename2, 'r') as f2:\n",
        "      for line in f2:\n",
        "        male_list.append(line.strip())\n",
        "\n",
        "    with open(filename3, 'r') as f3:\n",
        "      for line in f3:\n",
        "        gender_neutral_list.append(line.strip())\n",
        "    \n",
        "    return female_list, male_list, gender_neutral_list\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8y7qa8_GoWi",
        "outputId": "a245d413-4b0a-4476-a334-3d56df6ed804"
      },
      "source": [
        "# get different lists \n",
        "female_list, male_list, gender_neutral_list = read_gender_list('/content/gdrive/MyDrive/female_word_file.txt','/content/gdrive/MyDrive/male_word_file.txt', '/content/gdrive/MyDrive/gender_neutral.txt') \n",
        "print(\"Female list has the length of\", len(female_list))\n",
        "print(\"Male list has the length of\", len(male_list))\n",
        "print(\"Gender neutral list has the length of\", len(gender_neutral_list))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Female list has the length of 222\n",
            "Male list has the length of 222\n",
            "Gender neutral list has the length of 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM_uxXBtetV-",
        "outputId": "6f887b1a-b566-4b91-c72e-7878f4599cdf"
      },
      "source": [
        "# Clean the input data\n",
        "gender_list = []\n",
        "\n",
        "for element in female_list:\n",
        "  if element in indxr and element in indxr_gn:\n",
        "    gender_list.append(element)\n",
        "\n",
        "for element in male_list:\n",
        "  if element in indxr and element in indxr_gn:\n",
        "    gender_list.append(element)\n",
        "\n",
        "for element in gender_neutral_list:\n",
        "  if element not in indxr or element not in indxr_gn:\n",
        "    gender_neutral_list.remove(element)\n",
        "\n",
        "print(len(gender_list))\n",
        "print(len(gender_neutral_list))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "351\n",
            "149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR_PBAwkG-3E"
      },
      "source": [
        "def compute_similarity(gender_list, gender_neutral_list, indxr, wembs):\n",
        "  result = {}\n",
        "  for element in gender_neutral_list:\n",
        "    total = 0 \n",
        "    count = 0\n",
        "    element_emb = wembs[indxr[element]] \n",
        "\n",
        "    for target in gender_list:\n",
        "      target_emb = wembs[indxr[target]]\n",
        "      total += similarity(element_emb,target_emb)\n",
        "      count += 1\n",
        "    \n",
        "    average_simliarity = total / count \n",
        "    result[element] = average_simliarity\n",
        "  return result "
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_DEiuT6S1xT",
        "outputId": "a9ea41a0-f9bc-4c4d-e23b-8ddcfe598623"
      },
      "source": [
        "result = compute_similarity(gender_list, gender_neutral_list, indxr, wembs)\n",
        "print(result)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'advisors': -0.017638905430534233, 'attorney': 0.02989479490095007, 'retailer': -0.004847755246976582, 'professor': 0.04064898877016027, 'colleagues': 0.06543619156620575, 'advisor': 0.01562557455406406, 'co-host': 0.030610328457643284, 'barber': 0.06176488219229658, 'teachers': 0.06660149546563147, 'teacher': 0.11815133507810259, 'expert': -0.0020193594250522873, 'maker': -0.0011279128929816491, 'workers': 0.021473632954043753, 'worker': 0.07398994862108474, 'employee': 0.04961048289079744, 'employees': 0.019839489742394904, 'employer': 0.05602225868642091, 'employers': 0.016327619111896462, 'rapper': 0.05872884728689248, 'rappers': 0.04938647504198916, 'supervisor': 0.03284497342111891, 'manager': 0.01714324524155358, 'journalist': 0.06406443315287019, 'journalists': 0.02066878608812765, 'human': 0.019912460793100623, 'historian': 0.02594437014873785, 'artist': 0.07192584436704709, 'singer': 0.10125621675480347, 'mayor': 0.046635635595743095, 'scientist': 0.03705588399275073, 'scientists': 0.001077725956450799, 'lawyer': 0.07209949670303571, 'lawyers': 0.04581474960088926, 'tenant': 0.04759561099369933, 'gambler': 0.0746810346030799, 'geographer': 0.0011943747778853358, 'accountant': 0.06708799277425262, 'tutor': 0.10671516671395118, 'tutors': 0.08447808906375548, 'guide': 0.04222541337971353, 'communicator': 0.02098945786034577, 'landlord': 0.10199107269918, 'player': 0.04505627646088226, 'players': 0.04015528072088653, 'officer': 0.036740421307393654, 'officers': 0.033066898869146495, 'student': 0.06816090736474005, 'students': 0.049022961901795066, 'president': 0.029039925754634304, 'spokesman': -0.019070298194270963, 'banker': 0.06955717233100119, 'bankers': 0.004988004584899623, 'broker': 0.0015844524339232633, 'brokers': 0.0047738862469881285, 'programmer': 0.01728669902325773, 'programmers': 0.0019076386229370003, 'cheerleader': 0.08902027048388118, 'cheerleaders': 0.0743412560388495, 'analyst': -0.022143302609865422, 'analysts': -0.050287272461291055, 'solider': 0.030342466771062983, 'soliders': 0.05639264071994689, 'trader': 0.012892582025926457, 'traders': -0.012903799771065276, 'photographer': 0.06286576444413497, 'photographers': 0.047366634540024856, 'director': 0.011871969232440731, 'directors': 0.018178923818279118, 'engineer': 0.022421360823823802, 'engineers': -0.019660234472587787, 'ballplayers': 0.07665596740941398, 'teammate': 0.050890031236876535, 'teammates': 0.06797626625934926, 'producer': 0.01899229862121635, 'producers': 0.0023517852420732776, 'undergraduate': 0.02578413943918356, 'graduate': 0.05380883007865533, 'coauthor': 0.0030318538318454408, 'author': 0.0701461320811065, 'authors': 0.03444892731092023, 'cook': 0.047607403099799585, 'chef': 0.07897158570059402, 'chefs': 0.06420360236041824, 'owner': 0.071683403185909, 'owners': 0.05016938500801549, 'homeowner': 0.028191112215369032, 'homeowners': -0.002767132538689417, 'celebrity': 0.08362825530480135, 'attendee': 0.018202074432151688, 'attendees': 0.011426288919408457, 'teenager': 0.12078557255968478, 'teenagers': 0.10446157455643304, 'teen': 0.12313300814345539, 'teens': 0.09929743673948958, 'researcher': 0.013376643460796814, 'carpenter': 0.07472620450749913, 'driver': 0.05209115046545343, 'drivers': 0.02484231697931911, 'advertiser': -0.002630777473655341, 'advertisers': 0.0019690094098301155, 'leader': 0.035378379242576814, 'leaders': 0.018525647580699273, 'minister': 0.01862324326431614, 'customers': 0.013923988366113735, 'customer': 0.010171193603736294, 'voters': 0.01476747986649063, 'voter': -0.013143018304842848, 'consumers': -0.01929644548672111, 'consumer': -0.05156408223774192, 'reporter': 0.05519216738638988, 'reporters': 0.016129582730098558, 'staff': 0.021541430205554886, 'taxpayer': -0.0011854898636021402, 'taxpayers': -0.001811036671521685, 'hero': 0.09261206126884676, 'librarian': 0.09560018293310497, 'politicians': 0.04775623788165777, 'politician': 0.06988853799895489, 'civilian': -0.00836691739290639, 'civilians': 0.014678420904072426, 'guardian': 0.07843133833206235, 'musicians': 0.056418202192900085, 'musician': 0.08236394869691491, 'physician': 0.06544676346858079, 'physicians': 0.03611342499183439, 'comedian': 0.07043237150270758, 'comedians': 0.06212691023436333, 'pedestrian': -0.02201175933793844, 'pedestrians': 0.0013312503710943744, 'pianist': 0.07732340778560275, 'pianists': 0.057054244466784344, 'technicians': -0.007583694260345778, 'technician': 0.022798485648561448, 'vegetarian': 0.059066703381433446, 'farmer': 0.09553835184897469, 'farmers': 0.021171928486917624, 'electrician': 0.07511427814801118, 'attacker': 0.054543592675286655, 'bartender': 0.11476863814251786, 'stripper': 0.10720530930674861, 'boss': 0.07764935632066042, 'mathematician': 0.04362462197697767, 'instructor': 0.05743151068718247, 'lecturer': 0.04114288160763553, 'creator': 0.05474798467575392, 'creators': 0.03003917291529842, 'co-worker': 0.08683436123035629}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akpQIa4THE-c"
      },
      "source": [
        "result = compute_similarity(gender_list, gender_neutral_list, indxr, wembs)\n",
        "result_hard = compute_similarity(gender_list, gender_neutral_list, indxr, debiased_wembs)\n",
        "result_gn =  compute_similarity(gender_list, gender_neutral_list, indxr_gn, wembs_gn )"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UOtm_1xHgh-",
        "outputId": "2ceb4c3c-1d91-4ef5-f98f-ae7b97af5998"
      },
      "source": [
        "print(result)\n",
        "print(result_hard)\n",
        "print(result_gn)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'advisors': -0.017638905430534233, 'attorney': 0.02989479490095007, 'retailer': -0.004847755246976582, 'professor': 0.04064898877016027, 'colleagues': 0.06543619156620575, 'advisor': 0.01562557455406406, 'co-host': 0.030610328457643284, 'barber': 0.06176488219229658, 'teachers': 0.06660149546563147, 'teacher': 0.11815133507810259, 'expert': -0.0020193594250522873, 'maker': -0.0011279128929816491, 'workers': 0.021473632954043753, 'worker': 0.07398994862108474, 'employee': 0.04961048289079744, 'employees': 0.019839489742394904, 'employer': 0.05602225868642091, 'employers': 0.016327619111896462, 'rapper': 0.05872884728689248, 'rappers': 0.04938647504198916, 'supervisor': 0.03284497342111891, 'manager': 0.01714324524155358, 'journalist': 0.06406443315287019, 'journalists': 0.02066878608812765, 'human': 0.019912460793100623, 'historian': 0.02594437014873785, 'artist': 0.07192584436704709, 'singer': 0.10125621675480347, 'mayor': 0.046635635595743095, 'scientist': 0.03705588399275073, 'scientists': 0.001077725956450799, 'lawyer': 0.07209949670303571, 'lawyers': 0.04581474960088926, 'tenant': 0.04759561099369933, 'gambler': 0.0746810346030799, 'geographer': 0.0011943747778853358, 'accountant': 0.06708799277425262, 'tutor': 0.10671516671395118, 'tutors': 0.08447808906375548, 'guide': 0.04222541337971353, 'communicator': 0.02098945786034577, 'landlord': 0.10199107269918, 'player': 0.04505627646088226, 'players': 0.04015528072088653, 'officer': 0.036740421307393654, 'officers': 0.033066898869146495, 'student': 0.06816090736474005, 'students': 0.049022961901795066, 'president': 0.029039925754634304, 'spokesman': -0.019070298194270963, 'banker': 0.06955717233100119, 'bankers': 0.004988004584899623, 'broker': 0.0015844524339232633, 'brokers': 0.0047738862469881285, 'programmer': 0.01728669902325773, 'programmers': 0.0019076386229370003, 'cheerleader': 0.08902027048388118, 'cheerleaders': 0.0743412560388495, 'analyst': -0.022143302609865422, 'analysts': -0.050287272461291055, 'solider': 0.030342466771062983, 'soliders': 0.05639264071994689, 'trader': 0.012892582025926457, 'traders': -0.012903799771065276, 'photographer': 0.06286576444413497, 'photographers': 0.047366634540024856, 'director': 0.011871969232440731, 'directors': 0.018178923818279118, 'engineer': 0.022421360823823802, 'engineers': -0.019660234472587787, 'ballplayers': 0.07665596740941398, 'teammate': 0.050890031236876535, 'teammates': 0.06797626625934926, 'producer': 0.01899229862121635, 'producers': 0.0023517852420732776, 'undergraduate': 0.02578413943918356, 'graduate': 0.05380883007865533, 'coauthor': 0.0030318538318454408, 'author': 0.0701461320811065, 'authors': 0.03444892731092023, 'cook': 0.047607403099799585, 'chef': 0.07897158570059402, 'chefs': 0.06420360236041824, 'owner': 0.071683403185909, 'owners': 0.05016938500801549, 'homeowner': 0.028191112215369032, 'homeowners': -0.002767132538689417, 'celebrity': 0.08362825530480135, 'attendee': 0.018202074432151688, 'attendees': 0.011426288919408457, 'teenager': 0.12078557255968478, 'teenagers': 0.10446157455643304, 'teen': 0.12313300814345539, 'teens': 0.09929743673948958, 'researcher': 0.013376643460796814, 'carpenter': 0.07472620450749913, 'driver': 0.05209115046545343, 'drivers': 0.02484231697931911, 'advertiser': -0.002630777473655341, 'advertisers': 0.0019690094098301155, 'leader': 0.035378379242576814, 'leaders': 0.018525647580699273, 'minister': 0.01862324326431614, 'customers': 0.013923988366113735, 'customer': 0.010171193603736294, 'voters': 0.01476747986649063, 'voter': -0.013143018304842848, 'consumers': -0.01929644548672111, 'consumer': -0.05156408223774192, 'reporter': 0.05519216738638988, 'reporters': 0.016129582730098558, 'staff': 0.021541430205554886, 'taxpayer': -0.0011854898636021402, 'taxpayers': -0.001811036671521685, 'hero': 0.09261206126884676, 'librarian': 0.09560018293310497, 'politicians': 0.04775623788165777, 'politician': 0.06988853799895489, 'civilian': -0.00836691739290639, 'civilians': 0.014678420904072426, 'guardian': 0.07843133833206235, 'musicians': 0.056418202192900085, 'musician': 0.08236394869691491, 'physician': 0.06544676346858079, 'physicians': 0.03611342499183439, 'comedian': 0.07043237150270758, 'comedians': 0.06212691023436333, 'pedestrian': -0.02201175933793844, 'pedestrians': 0.0013312503710943744, 'pianist': 0.07732340778560275, 'pianists': 0.057054244466784344, 'technicians': -0.007583694260345778, 'technician': 0.022798485648561448, 'vegetarian': 0.059066703381433446, 'farmer': 0.09553835184897469, 'farmers': 0.021171928486917624, 'electrician': 0.07511427814801118, 'attacker': 0.054543592675286655, 'bartender': 0.11476863814251786, 'stripper': 0.10720530930674861, 'boss': 0.07764935632066042, 'mathematician': 0.04362462197697767, 'instructor': 0.05743151068718247, 'lecturer': 0.04114288160763553, 'creator': 0.05474798467575392, 'creators': 0.03003917291529842, 'co-worker': 0.08683436123035629}\n",
            "{'advisors': -0.012818726830841704, 'attorney': 0.032648192747786006, 'retailer': -0.019453990320935758, 'professor': 0.04398508907581103, 'colleagues': 0.07335365322380563, 'advisor': 0.02908344818066273, 'co-host': 0.01827996725966751, 'barber': 0.05648191967964971, 'teachers': 0.06412006478499661, 'teacher': 0.11491397889137094, 'expert': 0.002232330010997606, 'maker': 0.005310222885352613, 'workers': 0.021780772199031677, 'worker': 0.06635796992093619, 'employee': 0.03896313568686252, 'employees': 0.013926082831301987, 'employer': 0.045942122292935046, 'employers': 0.0040070822082682285, 'rapper': 0.06250764979950145, 'rappers': 0.048556360947532816, 'supervisor': 0.017973959214310622, 'manager': 0.016747273912519452, 'journalist': 0.0671048358246892, 'journalists': 0.021999927781699465, 'human': 0.022067037239699643, 'historian': 0.028512770412420348, 'artist': 0.05857216548648214, 'singer': 0.09022322692560932, 'mayor': 0.04817412514802004, 'scientist': 0.04655115592052036, 'scientists': 0.003294028148828696, 'lawyer': 0.07416636956592834, 'lawyers': 0.049373430101733194, 'tenant': 0.03947768089968278, 'gambler': 0.08783855925667852, 'geographer': 0.007104167066642408, 'accountant': 0.0705403293633616, 'tutor': 0.10999638527574766, 'tutors': 0.08191007588047862, 'guide': 0.037379769793754354, 'communicator': 0.02085444342208173, 'landlord': 0.09528374373307104, 'player': 0.048858577689640074, 'players': 0.048079117755697134, 'officer': 0.03813735450805333, 'officers': 0.04361759187305211, 'student': 0.06730083372117465, 'students': 0.04790775686168578, 'president': 0.03812660001655106, 'spokesman': -0.0028118083975845914, 'banker': 0.0827148541017014, 'bankers': 0.009588364634751434, 'broker': -0.002344019361826888, 'brokers': -0.005092995314507717, 'programmer': 0.01280909582840748, 'programmers': -0.006997369777609108, 'cheerleader': 0.07929107178541794, 'cheerleaders': 0.06940746935009581, 'analyst': -0.02135327872880052, 'analysts': -0.050445561855778434, 'solider': 0.034263875833049726, 'soliders': 0.06326195565257278, 'trader': 0.017414057559898447, 'traders': -0.012726286996844293, 'photographer': 0.05545934417208414, 'photographers': 0.0384532325364774, 'director': 0.011264341406491027, 'directors': 0.014217239751527506, 'engineer': 0.035555143814169826, 'engineers': -0.016883008852120452, 'ballplayers': 0.08366281877803072, 'teammate': 0.058728764596720634, 'teammates': 0.07195973472387991, 'producer': 0.012811037335277798, 'producers': -0.009770681660530092, 'undergraduate': 0.02856257957064611, 'graduate': 0.049061387085862725, 'coauthor': 0.011832662985565139, 'author': 0.06675105527526787, 'authors': 0.025498389281790643, 'cook': 0.027428559437659945, 'chef': 0.06777943540560764, 'chefs': 0.05083534529248697, 'owner': 0.06910046514027655, 'owners': 0.04569193087642196, 'homeowner': 0.021668237778534077, 'homeowners': -0.01453968243307152, 'celebrity': 0.06832745612037248, 'attendee': 0.012874781120951587, 'attendees': 0.0077253357940545025, 'teenager': 0.11156258135460342, 'teenagers': 0.09485921384873812, 'teen': 0.10785886353990234, 'teens': 0.08659651526227531, 'researcher': 0.01472756430910894, 'carpenter': 0.06775007991745567, 'driver': 0.05427121200834462, 'drivers': 0.024566590644176673, 'advertiser': -0.012749649837680644, 'advertisers': -0.00613424205675051, 'leader': 0.06566707764984112, 'leaders': 0.04489020399117189, 'minister': 0.03647175467601102, 'customers': -0.0018053256867167215, 'customer': -0.008058375087932957, 'voters': 0.014876605824085877, 'voter': -0.013874692153638237, 'consumers': -0.03205108883885281, 'consumer': -0.06226280170528715, 'reporter': 0.04665272025324596, 'reporters': 0.02214839057510847, 'staff': 0.022476962644378366, 'taxpayer': 0.0011778520445977485, 'taxpayers': 0.0018256416576847454, 'hero': 0.11336704920195463, 'librarian': 0.08502459942355502, 'politicians': 0.06184168645577254, 'politician': 0.0854910065181331, 'civilian': -0.005058247553716353, 'civilians': 0.02344206118428155, 'guardian': 0.07223879988147162, 'musicians': 0.05382579693823389, 'musician': 0.08372272694893129, 'physician': 0.06930418628809078, 'physicians': 0.030729936271918307, 'comedian': 0.06562985088169171, 'comedians': 0.05604320488648367, 'pedestrian': -0.028526933786985405, 'pedestrians': -0.006557672010101894, 'pianist': 0.07287911997094114, 'pianists': 0.05524130470120221, 'technicians': -0.010183064892557376, 'technician': 0.019586814522542465, 'vegetarian': 0.048476342890921315, 'farmer': 0.10424569671278441, 'farmers': 0.02778745498204744, 'electrician': 0.08609846838227617, 'attacker': 0.05739974654477548, 'bartender': 0.10681965241264113, 'stripper': 0.09571927189759648, 'boss': 0.08540452971546467, 'mathematician': 0.05385374731181633, 'instructor': 0.05581846383786601, 'lecturer': 0.042575651422395604, 'creator': 0.04914049038565601, 'creators': 0.01634786403106425, 'co-worker': 0.07229614982751466}\n",
            "{'advisors': 0.038767806961609357, 'attorney': -0.005380116473991553, 'retailer': -0.03926305830073476, 'professor': 0.011065165427750774, 'colleagues': 0.006375025033159115, 'advisor': 0.010493030675977217, 'co-host': 0.0861927289813025, 'barber': 0.15045130656810127, 'teachers': 0.013671449510083318, 'teacher': 0.06258878348108295, 'expert': -0.039922670045249214, 'maker': -0.054562852402121505, 'workers': -0.06387138273844352, 'worker': 0.009544176757494385, 'employee': -0.008744185856945674, 'employees': -0.05821764914706109, 'employer': 0.013336709459396396, 'employers': -0.03331362395991738, 'rapper': 0.07343350600145007, 'rappers': 0.11981866175284774, 'supervisor': 0.051562251746341804, 'manager': -0.05490704472016364, 'journalist': 0.052125933158928044, 'journalists': -0.010794380006168953, 'human': -0.0478142580289453, 'historian': 0.04126596255258378, 'artist': 0.0441491659168168, 'singer': 0.05800189933882981, 'mayor': 0.003970794254010509, 'scientist': 0.022731523966282627, 'scientists': -0.047524296618066036, 'lawyer': 0.02007295275997279, 'lawyers': -0.018979233579005564, 'tenant': 0.0763416826829988, 'gambler': 0.11867759503400886, 'geographer': 0.10204434037378228, 'accountant': 0.09612849343271405, 'tutor': 0.14855951860592348, 'tutors': 0.10243502579163284, 'guide': -0.002501914540977778, 'communicator': 0.10471634498071121, 'landlord': 0.0962410135986508, 'player': -0.027417101507167845, 'players': -0.04027572990091037, 'officer': -0.01781049837132169, 'officers': -0.03300755433831439, 'student': 0.004979106992721597, 'students': -0.034539927283266825, 'president': -0.06119896241193056, 'spokesman': -0.08570692946415162, 'banker': 0.06839603890015901, 'bankers': -0.005279948552246043, 'broker': 0.0011889298385568566, 'brokers': -0.002931866087436483, 'programmer': 0.09550113625716329, 'programmers': 0.048240831124895134, 'cheerleader': 0.1407271589468566, 'cheerleaders': 0.10496493014339904, 'analyst': -0.06889600869406451, 'analysts': -0.11621565700444592, 'solider': 0.11872330578062698, 'soliders': 0.14797919217665353, 'trader': 0.024738195222094347, 'traders': -0.03677873792481189, 'photographer': 0.05799842310760798, 'photographers': 0.06360605889043933, 'director': -0.06535549744809911, 'directors': -0.01415925999695466, 'engineer': 0.031140801405607953, 'engineers': -0.015486352014205177, 'ballplayers': 0.14235289026519116, 'teammate': 0.05377380107032816, 'teammates': 0.05954753729948399, 'producer': -0.021657632270995462, 'producers': -0.02727877567110676, 'undergraduate': 0.04725011253422465, 'graduate': 0.01850913751533353, 'coauthor': 0.08189316709789655, 'author': 0.006009318163777587, 'authors': -0.0028828216931356117, 'cook': 0.08443420420054917, 'chef': 0.06897949809176615, 'chefs': 0.07798958976283832, 'owner': -0.008240208146919253, 'owners': -0.037812206360867184, 'homeowner': 0.05565539511105061, 'homeowners': -0.042456105664726226, 'celebrity': 0.05404396899876208, 'attendee': 0.07339655766983319, 'attendees': 0.01340605377505484, 'teenager': 0.11336677524880565, 'teenagers': 0.07025487755942826, 'teen': 0.10586071701504803, 'teens': 0.07779405770425316, 'researcher': -0.01295638670359465, 'carpenter': 0.17017672138129564, 'driver': 0.007540952557862137, 'drivers': -0.029273196663100708, 'advertiser': 0.050947220154295585, 'advertisers': -0.005209129237963742, 'leader': -0.04576828511983384, 'leaders': -0.05889995456484592, 'minister': -0.031624478930458666, 'customers': -0.08523654562264824, 'customer': -0.05550207040284266, 'voters': -0.035477105806244615, 'voter': -0.019571202153718808, 'consumers': -0.10682770730235093, 'consumer': -0.11246669216764726, 'reporter': 0.04065547882873301, 'reporters': -0.04512567807751646, 'staff': -0.04632568463980985, 'taxpayer': -0.04192355020302292, 'taxpayers': -0.03758324197567923, 'hero': 0.07826217110137663, 'librarian': 0.12747450590823506, 'politicians': -0.009644216897042963, 'politician': 0.07286151484061683, 'civilian': -0.04009199193046654, 'civilians': -0.01372749566130483, 'guardian': 0.0926134082522428, 'musicians': 0.060140730946354644, 'musician': 0.11111108563146203, 'physician': 0.031362346116166874, 'physicians': -0.0006787892189063474, 'comedian': 0.08275826949590735, 'comedians': 0.11524073610284069, 'pedestrian': 0.03990209412616501, 'pedestrians': 0.04690162051585967, 'pianist': 0.11168215029858237, 'pianists': 0.11364643851757997, 'technicians': 0.03048296967939759, 'technician': 0.06406313360896337, 'vegetarian': 0.10499616312447141, 'farmer': 0.10146035472048864, 'farmers': -0.005477021841321376, 'electrician': 0.1317431084655875, 'attacker': 0.08365762588980065, 'bartender': 0.16353775112729588, 'stripper': 0.15667030856802325, 'boss': 0.024611529464030613, 'mathematician': 0.13716903932226812, 'instructor': 0.09012787991069647, 'lecturer': 0.06559266845041496, 'creator': 0.0378695887935912, 'creators': 0.046297277427207, 'co-worker': 0.17182043135378222}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "oqjveMPMQHp5",
        "outputId": "4dcfb269-72e5-444a-dfcc-dd5071794148"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(len(list(result_hard.keys())))\n",
        "print(len(list(result_gn.keys())))\n",
        "key_list = list(result_hard.keys())\n",
        "for x in range(len(key_list)):\n",
        "  plt.scatter(x, result_hard[key_list[x]],c='red')\n",
        "  plt.scatter(x, result_gn[key_list[x]],c='blue')\n",
        "plt.savefig(\"/content/gdrive/MyDrive/result.png\")\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "147\n",
            "147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajysGKk0Ymui",
        "outputId": "c41fbcfc-f170-4530-d2c3-dba398aa493f"
      },
      "source": [
        "def average_cos(result):\n",
        "  sum = 0\n",
        "  for element in result:\n",
        "    sum += result[element]\n",
        "  average = sum / len(result)\n",
        "  return average\n",
        "\n",
        "print(average_cos(result))\n",
        "print(average_cos(result_hard))\n",
        "print(average_cos(result_gn))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.04048196892066513\n",
            "0.0393187439383838\n",
            "0.030750115775586777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn03fcuGXqxr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}